import os
import re
import openai
import json
import logging
logger = logging.getLogger(__name__)

# Default Model overwritten by .env file
#MODEL = "gpt-3.5-turbo"
MODEL = os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo")

# ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¤œå‡ºç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
POSITIVE_KEYWORDS = ["ã‚ã‚ŠãŒã¨ã†", "æ„Ÿè¬", "åŠ©ã‹ã£ãŸ", "ã™ã”ã„", "ç´ æ™´ã‚‰ã—ã„", "ãƒŠã‚¤ã‚¹", "thanks", "thank you", "thx",]

# ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµµæ–‡å­—ã‚­ãƒ¼ï¼‰
POSITIVE_REACTIONS = {
    '+1', 'thumbsup',    # ğŸ‘
    'heart',             # â¤ï¸
    'tada',              # ğŸ‰
    'clap',              # ğŸ‘
    'raised_hands',      # ğŸ™Œ
    'bow',               # ğŸ™‡
    'bowing_woman',      # ğŸ™‡â€â™€ï¸
    'bowing_man',        # ğŸ™‡â€â™‚ï¸
    'pray',              # ğŸ™ 
}

# ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šæ’é™¤ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
NEGATIVE_ANSWER_KEYWORDS = ["ã‚ã‹ã‚‰ãªã„", "çŸ¥ã‚‰ãªã„", "ã§ãã¾ã›ã‚“", "ã©ã†ã§ã—ã‚‡ã†", "å…ˆç”Ÿï¼Ÿ"]

# èª­ã¿è¾¼ã¿ï¼šã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
BASE_DIR = os.path.dirname(__file__)
with open(os.path.join(BASE_DIR, "guidelines.txt"), encoding="utf-8") as f:
    GUIDELINES = f.read()

# é …ç›®ç•ªå·ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æœ€å¤§å€¤ã‚’å–å¾—
# 1. å„è¡Œã®å…ˆé ­ã«ã‚ã‚‹ã€Œæ•°å­—.ã€ã‚’å…¨éƒ¨æŠœãå‡ºã—ã¦æ•°å€¤åŒ–
numbers = [int(m.group(1))
           for m in re.finditer(r'^\s*(\d+)\.', GUIDELINES, re.MULTILINE)]
# 2. æœ€å¤§ã®ç•ªå·ãŒé …ç›®æ•°
NUM_GUIDELINES = max(numbers) if numbers else 0

# ç•ªå·ä»˜ãè¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒƒãƒ—åŒ–
RULES_MAP = {
    int(m.group(1)): m.group(2).strip()
    for m in re.finditer(r'^\s*(\d+)\.\s*(.+)$', GUIDELINES, re.MULTILINE)
}

def classify_text(text: str) -> dict:
    """
    ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³é•ååˆ¤å®šã‚’ LLM ã§è¡Œã„ã€è¾æ›¸ã§è¿”ã™ã€‚
    {"violation": bool}
    ãƒ¢ãƒƒã‚¯ fallback ã‚‚å«ã‚€ã€‚
    """
    # ãƒ¢ãƒƒã‚¯ç‰ˆ: badword ãŒã‚ã‚Œã°é•å
    if "badword" in text.lower():
        return {"violation": True}
    # LLM åˆ¤å®šï¼ˆä¾‹: ChatGPTï¼‰
    if openai.api_key:
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¦ç´„ã‚’åŸ‹ã‚è¾¼ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŠ•ç¨¿ã‚’æ¸¡ã™
        messages = [
            {
                "role": "system",
                "content": (
                    "ã‚ãªãŸã¯ç ”ç©¶å®¤ã®Slackã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£é‹å–¶ãƒœãƒƒãƒˆã§ã™ã€‚ä»¥ä¸‹ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è¦ç´„(ç•ªå·ä»˜ã)ã§ã™ã€‚å…¨æ–‡ã‚’ã‚ˆãèª­ã¿ã€"
                    "æŠ•ç¨¿ãŒè¦ç´„é•åã‹ã©ã†ã‹ã€ã‹ã¤ã€é•åãªã‚‰ä½•ç•ªã«é•åã—ã¦ã„ã‚‹ã‹ã‚’ç•ªå·ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n\n"
                    f"{GUIDELINES}"
                )
            },
            {
                "role": "user",
                "content": (
                    f"æ¬¡ã®æŠ•ç¨¿ã«ã¤ã„ã¦:\n```{text}```\n"
                    "1) é•åã—ã¦ã„ã¾ã™ã‹ï¼ŸYes/No\n"
                    "2) é•åãªã‚‰ã€é•åã—ãŸè¦ç´„ç•ªå·ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æ•™ãˆã¦ãã ã•ã„ã€‚é•åãŒãªã„å ´åˆã¯ã€ç•ªå·ã¯ä¸€åˆ‡è¿”ã•ãªã„ã§ãã ã•ã„ã€‚"
                    #f"æ¬¡ã®SlackæŠ•ç¨¿ãŒã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è¦ç´„ã«é•åã—ã¦ã„ã‚‹ã‹ï¼Ÿ Yes ã‹ No ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n```{text}```"
                )
            }
        ]
        create_args = {"model": MODEL, "messages": messages,}
        logger.info(f"[LLM: {MODEL}] classify_text req: '{text[:80]}'")
        # gpt-3.5-turbo ç³»ã§ temperature=0 ã‚’ä½¿ã„ãŸã„å ´åˆ
        if not MODEL.startswith("o4-"):
            create_args["temperature"] = 0
        
        resp = openai.chat.completions.create(**create_args)
        out = resp.choices[0].message.content.strip()
        logger.info(f"[LLM: {MODEL}] classify_text resp: '{out[:80]}'")
        # è¿”ã‚Šå€¤ä¾‹:
        # Yes
        # 3,5
        text_lower = out.lower()
        violation = bool(re.search(r"\byes\b", text_lower))  # Yes/No åˆ¤å®š
        # é•åã‚ã‚Šã®å ´åˆã®ã¿ç•ªå·ã‚’æŠ½å‡ºã€ãã‚Œä»¥å¤–ã¯ç©ºãƒªã‚¹ãƒˆ
        if violation:
            # å…¨æ–‡ã‹ã‚‰ç•ªå·ã‚’æŠ½å‡º â†’ ã‚»ãƒƒãƒˆåŒ–ã—ã¦é‡è¤‡ã‚’é™¤ãã€ã‚½ãƒ¼ãƒˆ
            extracted = map(int, re.findall(r"\b[1-9]\d*\b", out))
            valid_rules = sorted({
                n for n in extracted
                if 1 <= n <= NUM_GUIDELINES
            })
        else:
            valid_rules = []
        return {"violation": violation, "rules": valid_rules}
    
    # API ã‚­ãƒ¼ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return {"violation": False}

'''
def detect_positive_feedback(text: str) -> list:
    """
    ä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ„Ÿè¬ãƒ»è³è³›ã®ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡ºã—ã€å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãƒªã‚¹ãƒˆã‚’è¿”ã™
    """
    if not any(kw in text for kw in POSITIVE_KEYWORDS):
        return []
    # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å½¢å¼ <@U12345>
    ids = re.findall(r"<@([A-Z0-9]+)>", text)
    return ids
'''

def detect_positive_feedback(text: str) -> list[str]:
    """
    LLMã« â€œã“ã®ç™ºè¨€ã¯ä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ„Ÿè¬ãƒ»ç§°è³›ãªã©ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å«ã‚“ã§ã„ã‚‹ã‹ï¼Ÿ å«ã‚“ã§ã„ã‚‹ãªã‚‰å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’è¿”ã—ã¦â€ ã¨èãã€‚
    """
    # ã¾ãšæ—§æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼ã§ã–ã£ãã‚Šãƒ•ã‚£ãƒ«ã‚¿
    if not any(kw in text for kw in POSITIVE_KEYWORDS):
        return []

    # OpenAI APIã‚­ãƒ¼ãŒãªã„å ´åˆã‚„ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã€å¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯ã§
    if not openai.api_key:
        return re.findall(r"<@([A-Z0-9]+)>", text)

    # LLM ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦
    try:
        system = "ã‚ãªãŸã¯Slackã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£é‹å–¶ãƒœãƒƒãƒˆã§ã™ã€‚"
        user_prompt = (
            "ä»¥ä¸‹ã®æŠ•ç¨¿ãŒä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ã€Œæ„Ÿè¬ã€ã‚„ã€Œç§°è³›ã€ãªã©ã®ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å«ã‚“ã§ã„ã‚‹ã‹ï¼Ÿ\n"
            f"æŠ•ç¨¿:```{text}```\n"
            "å«ã‚“ã§ã„ã‚‹å ´åˆã¯ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’JSONãƒªã‚¹ãƒˆã§ã€å«ã‚“ã§ã„ãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆ([])ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
        )
        create_args = {
            "model": MODEL,
            "messages": [
                {"role": "system", "content": system},
                {"role": "user", "content": user_prompt},
            ],
        }
        # o4-miniç³»ã¯temperatureæŒ‡å®šã—ãªã„
        if not MODEL.startswith("o4-"):
            create_args["temperature"] = 0

        logger.info(f"[LLM: {MODEL}] detect_positive_feedback req: '{text[:80]}'")
        resp = openai.chat.completions.create(**create_args)
        content = resp.choices[0].message.content.strip()
        logger.info(f"[LLM: {MODEL}] detect_positive_feedback resp: '{content[:80]}'")

        # LLMãŒ["Uxxxx"]ã®å½¢ã§è¿”ã™å ´åˆ
        ids = json.loads(content)
        if isinstance(ids, list):
            return ids
    except Exception as e:
        #print(f"LLM failed: {e}")  # å¿…è¦ã«å¿œã˜ã¦ãƒ­ã‚°
        pass

    # å¤±æ•—ã—ãŸã‚‰å¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯   
    return re.findall(r"<@([A-Z0-9]+)>", text)

'''
def is_likely_answer(text: str) -> bool:
    """
    è³ªå•ã¸ã®å›ç­”ã¨ã¿ãªã›ã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«åˆ¤å®š
    - ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ’é™¤
    - æœ€ä½æ–‡å­—æ•°
    """
    # ãƒã‚¬ãƒ†ã‚£ãƒ–è¡¨ç¾ãŒã‚ã‚‹ãªã‚‰å›ç­”é™¤å¤–
    for kw in NEGATIVE_ANSWER_KEYWORDS:
        if kw in text:
            return False
    # æœ€ä½æ–‡å­—æ•° (ä¾‹: 20å­—)
    return len(text) >= 20
'''

def is_likely_answer(question: str, answer: str) -> bool:
    """
    è³ªå•ã¸ã®å›ç­”ã¨ã¿ãªã›ã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«åˆ¤å®š
    LLM ã« {question, answer} ã‚’æ¸¡ã—ã¦ã€ŒYes/Noã€ã§å›ç­”åˆ¤å®šã€‚
    APIã‚­ãƒ¼ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ã€20æ–‡å­—ä»¥ä¸Šãªã‚‰å›ç­”ã¨ã¿ãªã™ã€‚
    """
    if openai.api_key:
        messages = [
            {"role": "system", "content": "ã‚ãªãŸã¯Slackã®QAã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£é‹å–¶ãƒœãƒƒãƒˆã§ã™ã€‚"},
            {"role": "user", "content":
                f"ä»¥ä¸‹ã¯è³ªå•ã§ã™ï¼š\n```{question}```\n"
                f"ä»¥ä¸‹ã¯ãã®è¿”ä¿¡ã§ã™ï¼š\n```{answer}```\n"
                "ã“ã®è¿”ä¿¡ã¯è³ªå•ã«å¯¾ã™ã‚‹é©åˆ‡ãªå›ç­”ã‹ï¼ŸYes/No ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
            },
        ]
        create_args = {"model": MODEL, "messages": messages}
        if not MODEL.startswith("o4-"):
            create_args["temperature"] = 0
        
        logger.info(f"[LLM: {MODEL}] is_likely_answer req: question='{question[:80]}', answer='{answer[:80]}'")
        resp = openai.chat.completions.create(**create_args)
        ans = resp.choices[0].message.content.strip().lower()
        logger.info(f"[LLM: {MODEL}] is_likely_answer resp: '{ans[:80]}'")

        return ans.startswith("yes")
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return len(answer) >= 20
